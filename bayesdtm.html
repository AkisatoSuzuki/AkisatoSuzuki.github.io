<!DOCTYPE html>

<html lang="en">

<head>

    <title>Akisato Suzuki - Bayesian statistics, causal inference, and decision theory</title>
    <meta charset="UTF-8">
    <link rel="stylesheet" href="style.css">

</head>

<body>

<h1 class="center">Akisato Suzuki</h1>

<h2 class="center">Statistical Programs</h2>

<p class="links">
<a href="index.html">Top page</a> |
<a href="research.html">Research Projects</a> |
<a href="papers.html">Publications and Working Papers</a> |
<a href="programs.html">Statistical Programs</a> |
<a href="blog.html">Data Science Blog</a>
</p>

<h3 class="sectitle">bayesdtm: A Bayesian Decision-Theoretic Model to Compute Expected Losses with and without an Intervention</h3>
Current version: 0.0.0.9001

<p>
The R package "bayesdtm" implements a Bayesian decision-theoretic model to compute expected losses given an intervention (in causal inference senses) and those without it across different ratios of the cost of the intervention to the cost of the status quo, and returns the plot of these expected losses. The package currently has a function only for outputs from Bayesian logistic regression. In this vignette, I explain how to install the package and how to use it. For a theoretical rationale for using this model, please refer to <a href="https://arxiv.org/abs/2008.10903" target="_blank">Suzuki (2020)</a>.
</p>

<p>
First, let's install the package. To do so, you need to have the <a href="https://CRAN.R-project.org/package=devtools" target="_blank">devtools package</a> (Wickham, Hester, and Chang 2020) installed.
</p>

<pre class="code">
# Install the devtools package to install a package from GitHub
install.packages("devtools")
  
# Install the ccdfpost package from GitHub
devtools::install_github("AkisatoSuzuki/bayesdtm")

</pre>

<p>
Now, let's generate some hypothetical data via simulation, to be used to produce posterior samples via Bayesian regression. I choose arbitrary values for all parameters.
</p>

<pre class="code">
set.seed(1)
x <- rnorm(1000, mean = 0, sd = 10)
set.seed(2)
y <- rbinom(1000, 1, 1/(1+exp(-(log(1) + rnorm(1, mean = log(0.5), sd = 0.1)*x) ) ) )
d <- data.frame(x, y)

</pre>

<p>
Now, let's estimate the effect of x on y using Bayesian logistic regression. I do so via the rstanarm package (Goodrich et al. 2020), which works in a very similar way to the standard glm function. You can find more details on rstanarm at <a href="https://mc-stan.org/rstanarm" target="_blanck">https://mc-stan.org/rstanarm</a>. For simplicity, I use the default priors here. To use the package for logistic regression, there are two caveats. First, The binary dependent variable must be coded so that the value of 1 means an undesirable event and the value of 0 means a desirable event. Second, the variable of an intervention must be coded so that a larger value means an effect to reduce the likelihood of an undesirable event.
</p>

<pre class="code">
# install.packages("rstanarm")
library(rstanarm)

# Bayesian logistic regression with default priors
m <- stan_glm(y ~ x, data = d, family = binomial(link = "logit"),
              iter = 10000, chains = 4, cores = 4, warmup = 1000, seed=3)

# Extract posterior samples as a data frame
postmat <- as.data.frame(m)

# Extract a vector of posterior samples for x
posterior <- postmat$x

# Compute the mean of posterior samples for the baseline log odds
pi <- mean(postmat$"(Intercept)")

</pre>

<p>
Once you have a vector of posterior samples for the causal variable of interest and the baseline log odds computed (here, I use the mean of the posterior samples of the constant), you can use the loss_logit function to compute expected losses, as follows.
<p>

<pre class="code">
library(bayesdtm)

results <- loss_logit(posterior = posterior, pi = pi)

# Display a table with the expected losses given an intervention, those given no intervention,
# and the different ratios of the cost of the intervention to the cost of the undesirable event.
results[[1]]

# Plot these results
results[[2]]

</pre>

<p>
The example here produces the following plot.

<p>
<img src="bayesdtm1.png" alt="bayesdtm example plot 1" class="imgresize">
</p>
  
<p>
In the above example, there is only one regressor. What if there is more than one regressor? In such a case, you use the posterior samples of the causal variable of interest as a main input for the loss_logit function and reduce those of the other regressors to the baseline log odds while holding the values of these regressors at some constant value. It is the same logic as when you estimate the fitted values of an outcome across different values of the causal variable while holding the remaining regressors constant. The below is an example, where x is the causal variable of interest and z is another regressor. I also specify md = log(.8), which means the practically relevant effect size is defined as smaller than an odds ratio of 0.8 (I use the log of the odds ratio because the input for this parameter must be in a log odds scale).
</p>

<pre class="code">
set.seed(1)
x <- rnorm(1000, mean = 0, sd = 10)
set.seed(2)
z <- rnorm(1000, mean = -4, sd = 10)
set.seed(3)
y <- rbinom(1000, 1, 1/(1+exp(-(log(1) + rnorm(1, mean = log(0.5), sd = 0.1)*x
                                + rnorm(1, mean = log(1.25), sd = 0.1)*z) ) ) )
d <- data.frame(x, z, y)

# Bayesian logistic regression with default priors
m <- stan_glm(y ~ x + z, data = d, family = binomial(link = "logit"),
              iter = 10000, chains = 4, cores = 4, warmup = 1000, seed=4)

# Extract posterior samples as a data frame
postmat <- as.data.frame(m)

# Extract a vector of posterior samples for x
posterior <- postmat$x

# Add the mean of posterior samples for z times the mean value of z,
# to the mean of posterior samples for the baseline log odds
pi <- mean(postmat$"(Intercept)") + mean(postmat$z) * mean(z)

# Use the loss_logit function
results <- loss_logit(posterior = posterior, pi = pi, md = log(0.8))
results[[1]]
results[[2]]

</pre>

<p>
The resulting plot is as follows.
</p>

<p>
  <img src="bayesdtm2.png" alt="bayesdtm example plot 2" class="imgresize">
</p>


<p>
References
</p>

<p>
Goodrich, Ben, Jonah Gabry, Imad Ali, and Sam Brilleman. 2020. "Rstanarm: Bayesian Applied Regression Modeling via Stan." https://mc-stan.org/rstanarm.
</p>

<p>
Suzuki, Akisato. 2020. "Policy Implications of Statistical Estimates: A General Bayesian Decision-Theoretic Model for Binary Outcomes." arXiv:2008.10903 [stat.ME]. https://arxiv.org/abs/2008.10903.
</p>

<p>
Wickham, Hadley, Jim Hester, and Winston Chang. 2020. "devtools: Tools to Make Developing R Packages Easier." R package version 2.3.0. https://CRAN.R-project.org/package=devtools.
</p>

</body>
</html>

